\documentclass[a4paper,14pt]{extarticle}

\input{includes/preamble}

\usepackage[backend=biber]{biblatex}

\addbibresource{includes/bibliography.bib}

\newcommand{\printbib}{
    \anonsection{Список использованных источников}
    \printbibliography[heading=none]
}

\begin{document}

\tableofcontents 
\clearpage

\anonsection{Введение}

Автоматическая обработка естественного языка -- популярная область исследований специалистов по машинному обучению. С развитием технологий появляется все больше задач, успешное решение которых требует сложных алгоритмов и больших затрат ресурсов.

Несмотря на то что задача распознавания именованных сущностей была сформулирована в 90-х годах 20 века, до сих пор нельзя утверждать, что она является полностью решенной: нет алгоритма, который решал бы задачу лучше, чем асессор. В настоящее время задача может рассматриваться как отдельная, а может и как часть большой системы. Таким образом, она является популярной (каждый год появляются новые, более успешные алгоритмы решения) и актуальной.

В данной работе изучаются различные методы решения задачи распознавания именованных сущностей. В частности, рассмотрены основные методы, придуманные в последние 4 года. Были реализованы подходы, описанные в статьях \cite{1603.01354} и \cite{1808.09075}. Над архитектурой, предложенной в последней статье, было проведено исследование. Была выдвинута, а впоследствии опровергнута гипотеза о возможном упрощении данной архитектуры.

\clearpage

\section{Постановка задачи}

\subsection{NER}

Распознавание именованных сущностей является важной подзадачей при извлечении информации из неструктурированных данных. В задаче, представленной на конференции CoNLL 2003, необходимо отнести каждое слово в предложении к одному из четырех классов: PER (человек), LOC (локация), ORG (организация), MISC (другое). Используется IOB-нотация: для сущностей, состоящих более чем из одного слова, необходимо определить начальное (B-) и все внутренние (I-) слова. Если слово не относится ни к одному из четырех классов, то оно помечается отдельно (O).

Т.к. задача распознавания именованных сущностей была сформулирована достаточно давно, то существует большое количество соревнований и различных датасетов, на которых ученые могут проверить свое решение. В данный момент большинство авторов статей сравнивают свои результаты на корпусе, который был представлен на конференции CoNLL 2003.

Отметим так же, что помимо IOB существуют и другие нотации. В частности, в этой работе используется IOBES-нотация (согласно \cite{ratinov-roth-2009-design}, \cite{1511.08308} эта схема позволяет получить более высокие результаты), а для подсчета качества распознавания она переводится в IOB-схему.

\subsection{Предмет исследования}

В \cite{1808.09075} был предложен эффективный способ использования дополнительных признаков для решения задачи распознавания именованных сущностей. В данной статье вводится автоэнкодер, который получает дополнительные признаки на вход, а затем возвращает их в качестве своего выхода.

Кроме того в \cite{1808.09075} было установлено, что выход автоэнкодера является важной составляющей успешного решения: если дополнительные признаки подавать только на вход, то качество не лучше, чем если их вообще не подавать.

Была выдвинута следующая гипотеза: можно отказаться от подачи автоэнкодеру на вход вручную сгенерированных признаков, оставив выход неизменным, причем итоговое качество модели не ухудшится.

\subsection{Актуальность работы}

Распознавание именованных сущностей может рассматриваться как отдельная задача (например, для поиска и защиты персональных данных в Интернете) или как часть большой системы (например, как составная часть голосового помощника). В обоих случаях будет полезно минимизировать ресурсы, необходимые для построения и поддержания качественного решения.

\clearpage

\section{Методы решения}

С 2016 года качество решения задачи распознавания именованных сущностей значительно увеличилось.

\begin{table}[H]
    \caption{Качество решения задачи NER}
    \label{progress}
    \begin{center}
    \begin{tabular}{l|c|c}
        Архитектура           & Год  & F1-score \\
        \hline
        CNN Large + fine-tune & 2019 & 93.5     \\
        BERT                  & 2018 & 92.8     \\
        ELMo                  & 2018 & 92.22    \\
        CRF + AutoEncoder     & 2018 & 91.87    \\
        LSTM-CRF              & 2016 & 91.21    \\
    \end{tabular}
    \end{center}
\end{table}

В данном разделе будут описаны самые важные подходы к решению рассматриваемой задачи.

\subsection{LSTM-CRF}

Стандартным нейросетевым подходом к решению задачи распознавания именованных сущностей можно считать следующую архитектуру: конкатенация символьных и словных эмбеддингов подается в двунаправленный LSTM; непосредственная классификация производится с помощью CRF.

В \cite{1603.01360} и \cite{1603.01354} были предложены два различных подхода к получению символьных эмбеддингов (такие подходы встречались и раньше, но именно эти работы считаются самыми успешными). Основная идея -- использование механизма, который может работать с данными произвольной длины. Для этого в \cite{1603.01360} используется рекуррентная нейронная сеть, а в \cite{1603.01354} -- сверточная.

\addtwoimghere{lample_embeddings.png}{lample_architecture.png}{0.49}{Символьные эмбеддинги и архитектура, предложенные в \cite{1603.01360}}{lample}

\addtwoimghere{ma_embeddings.png}{ma_architecture.png}{0.49}{Символьные эмбеддинги и архитектура, предложенные в \cite{1603.01354}}{ma}

% Hardcode for better appearance
\clearpage

\subsection{CRF + AutoEncoder}

Многие ученые пытались улучшить качество решения задачи распознавания именованных сущностей с помощью дополнительных признаков: POS-тэгов, данных из географических справочников, шаблонов капитализации. В то время как простое добавление этих данных не дает улучшений, в \cite{1808.09075} был предложен новый способ, который позволил увеличить F1-score примерно на 1\%. Авторы данной статьи предлагают помимо решения задачи распознавания именованных сущностей также решать задачу восстановления дополнительных признаков. Для этого вводится автоэнкодер и его функция потерь.

$$\mathcal{L}_{AE}^{t} = \sum_{i=0}^{T}{XEntropy(f_{i}^{t},\hat{f_{i}^{t}})}$$
$$\mathcal{L} = \mathcal{L}_{CRF} + \sum_{t}{\lambda_{t}\mathcal{L}_{AE}^{t}}$$

\addimghere{wu_architecture.png}{0.8}{Архитектура, предложенная в \cite{1808.09075}}{wu}

% Hardcode for better appearance
\clearpage

\subsection{ELMo}

В статье \cite{1802.05365} описывается способ получения эмбеддингов, которые будут учитывать не только синтаксические и семантические признаки, а также контекст рассматриваемого слова. Для этого используется многослойный двунаправленный LSTM, взвешенная сумма состояний которого и определяет вектор токена. Эмбеддинги, полученные таким способом, позволили улучшить качество решения сразу нескольких традиционных задач в области обработки естественного языка.

\addimghere{elmo_architecture.png}{1}{Архитектура ELMo}{elmo}

\subsection{BERT}

В 2018 году группа ученых из Google AI Language предложила универсальную архитектуру BERT (см. \cite{1810.04805}), которая позволила получить State-of-the-art результаты на большом числе NLP задач.

В то время как большинство языковых моделей работают только с одним из контекстов (левым или правым), в BERT применятся идея Masked LM -- часть слов предложения маскируется специальным символом, а затем эти слова предсказываются (получается, что учитываются все токены).

\addimghere{bert_procedures.png}{1}{Pre-training и Fine-Tuning -- два процесса, составляющих алгоритм}{bert_procedures}

Универсальность модели также обеспечивается следующими двумя факторами: на вход подается не одно, а два предложения; дополнительно решается задача NSP -- определяется, является ли второе предложение продолжением первого.

\addimghere{bert_input.png}{1}{На вход BERT подаются два предложения, разделенные специальным символом}{bert_input}

% Hardcode for better appearance
\clearpage

\subsection{CNN Large + fine-tune}

Еще более высокие результаты были опубликованы в \cite{1903.07785}. Как и в BERT, сначала происходит Pre-training, а затем -- Fine-tuning. Основными отличиями являются:
\begin{enumerate}
    \item Маскинг каждого токена, а не случайного набора
    \item Отсутствие необходимости решать задачу NSP
    \item Измененные блоки трансформера (см. \cite{1706.03762})
    \item Процесс обучения похож на процесс обучения классической языковой модели
\end{enumerate}

\clearpage

\section{Проделанная работа}

Для того чтобы лучше разобраться в исследуемой задаче, сначала были реализованы существующие подходы, а уже после этого проводились эксперименты.

Работа велась с данными, представленными на конференции CoNLL 2003. Основной метрикой качества является F1-score. Для дополнительных задач так же измерялась точность предсказаний.

\begin{table}[H]
    \caption{Датасет CoNLL 2003}
    \label{progress}
    \begin{center}
    \begin{tabular}{l|c}
        Данные                & Количество предложений \\
        \hline
        Обучающая выборка     & 14041                  \\
        Валидационная выборка & 3250                   \\
        Тестовая выборка      & 3453                   \\
    \end{tabular}
    \end{center}
\end{table}

\addimghere{conll_sentence.png}{0.4}{Пример обработанного предложения}{conll}

\subsection{Реализация существующих подходов}

Сначала была реализована архитектура, предложенная в статье \cite{1603.01354}. В отличие от оригинальной статьи была реализована возможность обучения с батчем произвольной длины. Это позволило ускорить процесс обучения, а также сделать его более стабильным.

\begin{table}[H]
    \caption{Параметры обучения}
    \label{progress}
    \begin{center}
    \begin{tabular}{l|c}
        Размер батча & 128 \\
        Размерность LSTM & 300 \\
        Размерность CNN & 30 \\
        Размер ядра CNN & 4 \\
        Размер фильтра CNN & 30 \\
        Dropout & 0.5 \\
        Recurrent dropout & 0.3 \\
        Предобученные эмбеддинги & GloVe.6B.100d \\
        Оптимизатор & Nadam \\
        Ограничение нормы градиента & 5 \\
    \end{tabular}
    \end{center}
\end{table}

\begin{table}[H]
    \caption{Сравнение качества реализации модели, представленной в \cite{1603.01354}}
    \label{progress}
    \begin{center}
    \begin{tabular}{l|c}
        Модель                 & F1-score \\
        \hline
        Ma \& Hovy             & 91.21    \\
        Полученная реализация  & 90.46    \\
    \end{tabular}
    \end{center}
\end{table}

Обучение производилось с использованием GPU NVIDIA Tesla K80. Процесс занял около 8 часов на Google Colaboratory. В результате получилась модель, уступающая оригинальной в качестве. Это может быть связано с тем, что не проводилась явная инициализация весов нейросети. Также возможно влияние используемого фреймворка и рабочей машины.

Следующий этап -- реализация архитектуры из статьи \cite{1808.09075}. Как и в предыдущем случае, было реализовано обучение с батчем произвольной длины.

\begin{table}[H]
    \caption{Параметры обучения лучшей модели}
    \label{progress}
    \begin{center}
    \begin{tabular}{l|c}
        Размер батча & 32 \\
        Размерность LSTM & 300 \\
        Размерность CNN & 25 \\
        Размер ядра CNN & 3 \\
        Размер фильтра CNN & 25 \\
        Dropout & 0.5 \\
        Recurrent dropout & 0.5 \\
        Предобученные эмбеддинги & GloVe.6B.300d \\
        Оптимизатор & SGD \\
        Learning rate & 0.015 \\
        Убывание весов & 1e-6 \\
        Момент & 0.9 \\
        Ограничение нормы градиента & 5 \\
    \end{tabular}
    \end{center}
\end{table}

\begin{table}[H]
    \caption{Сравнение качества реализации модели, представленной в \cite{1808.09075}}
    \label{progress}
    \begin{center}
    \begin{tabular}{l|c}
        Модель                 & F1-score           \\
        \hline
        Wu et al.              & 91.89 $\pm$ 0.23   \\
        Полученная реализация  & 91.64              \\
    \end{tabular}
    \end{center}
\end{table}

Обучение производилось с использованием GPU NVIDIA Tesla K80. Процесс занял около 8 часов на Google Colaboratory. В результате получилась модель, попадающая в заявленный в статье интервал.

\subsection{Исследование}

Основной целью работы являлась проверка следующей гипотезы: на вход автоэнкодеру (см. \cite{1808.09075}) можно не подавать сгенерированные вручную признаки. Остановимся на них подробнее.

Во-первых, это POS-тэги, которые указывают, какой частью речи является данное слово. Используется самая распространенная классификация -- каждое слово относится к одному из 45 классов. Так как обучение происходит с батчами, предложения в которых могут иметь разную длину, был добавлен еще один класс, обозначающий паддинг.

Во-вторых, используются шаблоны капитализации. Они показывают, есть ли в слове заглавные буквы, цифры и др. Всего авторам \cite{1808.09075} удалось выделить 151 класс. Здесь также был добавлен дополнительный класс для паддингов.

В-третьих, используются "газитиры" -- сведения из картографических справочников. Под них выделено 4 класса.

В \cite{1808.09075} можно подробно прочитать, как производился сбор и разметка этих дополнительных данных.

Согласно архитектуре, на вход автоэнкодер получает конкатенацию символьных и словных эмбеддингов, а также конкатенацию "газитиров", POS-тегов и шаблонов капитализации, причем последние два подаются в склеенном состоянии.

Помимо основной задачи NER, решается задача восстановления полученных на вход "газитиров", POS-тегов и шаблонов капитализации. Таким образом, у модели 4 выхода.

В данной работе проверяется, можно ли оставив выход нейросети прежним, отказаться от подачи на вход либо всех дополнительных признаков, либо только от POS-тегов и шаблонов капитализации.

\subsection{Результаты}

Для проверки гипотезы были обучены еще две нейросети. Одна получала на вход дополнительно "газитиры", другая не получала никаких дополнительных признаков.

\begin{table}[H]
    \caption{Параметры обучения моделей}
    \label{progress}
    \begin{center}
    \begin{tabular}{l|c|c}
        Параметры                   & С "газитирами" & Без дополнительных \\
                                    &                & признаков          \\
        \hline
        Размер батча                & 64             & 48                 \\
        Размерность LSTM            & 400            & 200                \\
        Размерность CNN             & 25             & 27                 \\
        Размер ядра CNN             & 4              & 3                  \\
        Размер фильтра CNN          & 25             & 27                 \\
        Dropout                     & 0.4            & 0.47               \\
        Recurrent dropout           & 0.5            & 0.47               \\
        Предобученные эмбеддинги    & GloVe.6B.300d  & GloVe.6B.300d      \\
        Оптимизатор                 & SGD            & SGD                \\
        Learning rate               & 0.03           & 0.04               \\
        Убывание весов              & 1e-5           & 5e-5               \\
        Момент                      & 0.9            & 0.9                \\
        Ограничение нормы градиента & 5              & 10                 \\
        Метод Нестерова             & Да             & Да                 \\
    \end{tabular}
    \end{center}
\end{table}

Обучение производилось с использованием GPU NVIDIA Tesla K80. Во всех случаях процесс занял около 8 часов на Google Colaboratory. Получились следующие результаты.

\begin{table}[H]
    \caption{Качество реализации оригинальной модели}
    \label{progress}
    \begin{center}
    \begin{tabular}{l|c|c}
                              & F1-score         & Accuracy \\
        \hline
        NER                   & 91.5 $\pm$ 0.1   &          \\
        POS-теги              & 98.90            & 98.90    \\
        Шаблоны капитализации & 99.02            & 99.02    \\
    \end{tabular}
    \end{center}
\end{table}

\begin{table}[H]
    \caption{Качество модели, принимающей на вход "газитиры"}
    \label{progress}
    \begin{center}
    \begin{tabular}{l|c|c}
                              & F1-score & Accuracy \\
        \hline
        NER                   & 91.05    &          \\
        POS-теги              & 88.83    & 94.98    \\
        Шаблоны капитализации & 65.09    & 98.12    \\
    \end{tabular}
    \end{center}
\end{table}

\begin{table}[H]
    \caption{Качество модели, не принимающей на вход дополнительных признаков}
    \label{progress}
    \begin{center}
    \begin{tabular}{l|c|c}
                              & F1-score & Accuracy \\
        \hline
        NER                   & 90.78    &          \\
        POS-теги              & 94.31    & 99.09    \\
        Шаблоны капитализации & 72.77    & 99.14    \\
    \end{tabular}
    \end{center}
\end{table}

В результате, достичь того же качества, что и в оригинальной статье, не удалось.

\subsection{Выводы}

Из результатов становится понятно, что отказаться от подачи дополнительных признаков на вход автоэнкодеру без потери качества нельзя.

Отчетливо видна связь между качеством решения основной задачи -- распознавания именованных сущностей, и между качеством решения вспомогательных задач -- восстановления дополнительных признаков. Не получая эти признаки на вход, автоэнкодер не позволяет нейросети правильно выучить веса, о чем говорят низкие результаты решения как основной, так и вспомогательных задач. Если же подавать дополнительную информацию на вход автоэнкодеру, то на обеих задачах наблюдаются высокие результаты. Это можно объяснить следующим образом: нейросеть выучивает общее представление о POS-тэгах и шаблонах капитализации, но не может восстановить важные данные, содержащиеся в оригинальных признаках.

Таким образом, для успешного решения задачи распознавания именованных сущностей необходимы какие-то определенные POS-тэги и шаблоны капитализации: F1-score говорит о том, что они действительно существуют, точность восстановления подсказывает, что они являются редкими, а их необходимость понятна из результатов исследования.

\clearpage

\anonsection{Заключение}

В данной работе были подробно изучены способы решения задачи распознавания именованных сущностей. Алгоритмы, предложенные в статьях \cite{1603.01354} и \cite{1808.09075} были успешно реализованы. Также проведено исследование архитектуры, рассматриваемой в последней статье. По результатам этого исследования была отвергнута гипотеза о возможном упрощении модели.

Исходный код моделей, их обучение и исследование, а также все необходимые данные и скрипты выложены в репозитории \footnote{\href{https://github.com/svinkapeppa/bachelor-thesis}{github.com/svinkapeppa/bachelor-thesis}} в открытом доступе.

\clearpage

\printbib

\end{document}
