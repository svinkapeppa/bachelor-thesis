{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dpq-EXJgCozJ"
   },
   "outputs": [],
   "source": [
    "!wget -qq https://raw.githubusercontent.com/svinkapeppa/trash/master/conlleval.py\n",
    "!wget -qq https://raw.githubusercontent.com/svinkapeppa/trash/master/utils.py\n",
    "!wget -qq https://raw.githubusercontent.com/svinkapeppa/trash/master/install\n",
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTafd3i_C23W"
   },
   "outputs": [],
   "source": [
    "!chmod 777 install\n",
    "!./install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z6tPnKEMDKhP",
    "outputId": "dede00c4-7cad-4191-dfb1-d01105225c15"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import TimeDistributed, Conv1D, Dense, Embedding, Input, Dropout, LSTM, Bidirectional, MaxPooling1D, Flatten, concatenate\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import Nadam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "\n",
    "import utils\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tr5FGuU4Dj6p"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 128\n",
    "LSTM_DIM = 300\n",
    "CHAR_EMB_DIM = 30\n",
    "KERNEL_SIZE = 4\n",
    "CHAR_FILTERS = 30\n",
    "DROPOUT = 0.5\n",
    "RECURRENT_DROPOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features/all_onehot.train', 'rb') as f:\n",
    "    features_train = pickle.load(f)\n",
    "with open('features/all_onehot.testa', 'rb') as f:\n",
    "    features_dev = pickle.load(f)\n",
    "with open('features/all_onehot.testb', 'rb') as f:\n",
    "    features_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features/gazetteer_PERLOC.train', 'rb') as f:\n",
    "    gaze_train = pickle.load(f)\n",
    "with open('features/gazetteer_PERLOC.testa', 'rb') as f:\n",
    "    gaze_dev = pickle.load(f)\n",
    "with open('features/gazetteer_PERLOC.testb', 'rb') as f:\n",
    "    gaze_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "guW466erDkMB",
    "outputId": "e4cf7861-0d6c-4947-a15d-c9cd06ed5c44"
   },
   "outputs": [],
   "source": [
    "train_sentences = utils.read_sentences('data/train')\n",
    "valid_sentences = utils.read_sentences('data/valid')\n",
    "test_sentences = utils.read_sentences('data/test')\n",
    "\n",
    "print('Number of TRAIN sentences: {}'.format(len(train_sentences)))\n",
    "print('Number of VALID sentences: {}'.format(len(valid_sentences)))\n",
    "print('Number of TEST sentences: {}'.format(len(test_sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79-ICpaoDlUy"
   },
   "outputs": [],
   "source": [
    "utils.convert_tags(train_sentences)\n",
    "utils.convert_tags(valid_sentences)\n",
    "utils.convert_tags(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w49kFKYWDmXR"
   },
   "outputs": [],
   "source": [
    "tag_idx, idx_tag = utils.create_tag_mapping([train_sentences, valid_sentences, test_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xCM5uXQuDnX9"
   },
   "outputs": [],
   "source": [
    "word_idx, idx_word, word_embeddings = utils.create_word_mapping('glove/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3auIiUlpDojp"
   },
   "outputs": [],
   "source": [
    "char_idx, idx_char = utils.create_char_mapping([train_sentences, valid_sentences, test_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgWNhZSeDpmY"
   },
   "outputs": [],
   "source": [
    "case_idx, case_embeddings = utils.create_case_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGiPrxPBDqhU"
   },
   "outputs": [],
   "source": [
    "max_word_length = utils.get_max_word_length([train_sentences, valid_sentences, test_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.add_auxiliary_information(train_sentences)\n",
    "utils.add_auxiliary_information(valid_sentences)\n",
    "utils.add_auxiliary_information(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaIxTlUBDrjj"
   },
   "outputs": [],
   "source": [
    "train_batches = utils.create_batches(train_sentences, BATCH_SIZE, max_word_length, word_idx,\n",
    "                                     char_idx, tag_idx, features_train, gaze_train)\n",
    "valid_batches = utils.create_batches(valid_sentences, BATCH_SIZE, max_word_length, word_idx,\n",
    "                                     char_idx, tag_idx, features_dev, gaze_dev)\n",
    "test_batches = utils.create_batches(test_sentences, BATCH_SIZE, max_word_length, word_idx,\n",
    "                                    char_idx, tag_idx, features_test, gaze_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmKNYY7iDsgT"
   },
   "outputs": [],
   "source": [
    "def CharCNNBiLSTM(word_vocab_size, case_vocab_size, char_vocab_size,\n",
    "                  word_embeddings_dim, case_embeddings_dim, max_word_length,\n",
    "                  word_embeddings, case_embeddings, tag_set_size):\n",
    "    word_input = Input(shape=(None,))\n",
    "    word_embeddings = Embedding(\n",
    "        word_vocab_size, word_embeddings_dim, weights=[word_embeddings], trainable=True\n",
    "    )(word_input)\n",
    "\n",
    "    case_input = Input(shape=(None,))\n",
    "    case_embeddings = Embedding(\n",
    "        case_vocab_size, case_embeddings_dim, weights=[case_embeddings], trainable=True\n",
    "    )(case_input)\n",
    "    \n",
    "    char_input = Input(shape=(None, max_word_length))\n",
    "    char_embeddings = TimeDistributed(Embedding(\n",
    "        char_vocab_size, CHAR_EMB_DIM, embeddings_initializer=RandomUniform(minval=-math.sqrt(0.1), maxval=math.sqrt(0.1))\n",
    "    ))(char_input)\n",
    "    char_embeddings = Dropout(DROPOUT)(char_embeddings)\n",
    "    char_embeddings = TimeDistributed(Conv1D(\n",
    "        kernel_size=KERNEL_SIZE, filters=CHAR_FILTERS, padding='same', activation='tanh', strides=1\n",
    "    ))(char_embeddings)\n",
    "    char_embeddings = TimeDistributed(MaxPooling1D(max_word_length))(char_embeddings)\n",
    "    char_embeddings = TimeDistributed(Flatten())(char_embeddings)\n",
    "\n",
    "    feature_input = Input(shape=(None, 196))\n",
    "    gaze_input = Input(shape=(None, 3))\n",
    "\n",
    "    embeddings = concatenate([word_embeddings, case_embeddings, char_embeddings, feature_input, gaze_input])\n",
    "    embeddings = Dropout(DROPOUT)(embeddings)\n",
    "    \n",
    "    output = Bidirectional(LSTM(\n",
    "        LSTM_DIM, return_sequences=True, dropout=DROPOUT, recurrent_dropout=RECURRENT_DROPOUT\n",
    "    ))(embeddings)\n",
    "\n",
    "    lstm = TimeDistributed(Dense(LSTM_DIM, activation='elu'))(output)\n",
    "    lstm = CRF(tag_set_size, sparse_target=True)(lstm)\n",
    "    gaze = TimeDistributed(Dense(3, activation='elu'))(output)\n",
    "    shape = TimeDistributed(Dense(151, activation='elu'))(output)\n",
    "    position = TimeDistributed(Dense(45, activation='elu'))(output)\n",
    "    \n",
    "    return Model(inputs=[word_input, case_input, char_input, feature_input, gaze_input], outputs=[lstm, gaze, shape, position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-MA4A3XDtwH"
   },
   "outputs": [],
   "source": [
    "model = CharCNNBiLSTM(len(word_idx), len(case_idx), len(char_idx),\n",
    "              len(word_embeddings[0]), len(case_idx), max_word_length,\n",
    "              word_embeddings, case_embeddings, len(tag_idx))\n",
    "model.compile(loss=[crf_loss, utils.weighted_sparse_categorical_crossentropy, sparse_categorical_crossentropy, sparse_categorical_crossentropy], optimizer=Nadam(clipnorm=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rWHfpJd3Dvie"
   },
   "outputs": [],
   "source": [
    "from conlleval import evaluate\n",
    "\n",
    "\n",
    "def evaluate_model(model, batches, idx_tag):\n",
    "    true_seqs, pred_seqs = [], []\n",
    "\n",
    "    for batch in batches:\n",
    "        target = batch['tag']\n",
    "        target = target.reshape((target.shape[0], target.shape[1]))\n",
    "        logits = model.predict([batch['word'], batch['case'], batch['char'], batch['features'], batch['gaze']], verbose=False)[0].argmax(axis=-1)\n",
    "\n",
    "        for seq_ind, seq_len in enumerate(batch['lengths']):\n",
    "            true_seqs.append(' '.join([idx_tag[ind.item()] for ind in target[seq_ind, 1: seq_len + 1]]))\n",
    "            pred_seqs.append(' '.join([idx_tag[ind.item()] for ind in logits[seq_ind, 1: seq_len + 1]]))\n",
    "\n",
    "    return evaluate(true_seqs, pred_seqs, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 12778
    },
    "colab_type": "code",
    "id": "p8xdzNgCDwsg",
    "outputId": "4a5e43cf-676c-4067-f8c5-e97e118379f0"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    random.shuffle(train_batches)\n",
    "    \n",
    "    print('----------------------------------- EPOCH: {} -----------------------------------'.format(epoch))\n",
    "    print('----------------------------------- Training -----------------------------------')\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch in train_batches:\n",
    "        model.train_on_batch([batch['word'], batch['case'], batch['char'], batch['features'], batch['gaze']], [batch['tag'], batch['gazetteers'], batch['shape'], batch['position']])\n",
    "    \n",
    "    finish_time = time.time()\n",
    "    \n",
    "    print('Time: {:.2f}s'.format(finish_time - start_time))\n",
    "    \n",
    "    print('---------------------------------- Evaluating ----------------------------------')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    f, precision, recall = evaluate_model(model, train_batches, idx_tag)\n",
    "    \n",
    "    print('================================== Train Data ==================================')\n",
    "    print('F1 = {:.2f}%, Precision = {:.2f}%, Recall = {:.2f}%'.format(f, precision, recall))\n",
    "    \n",
    "    f, precision, recall = evaluate_model(model, valid_batches, idx_tag)\n",
    "    \n",
    "    print('================================== Valid Data ==================================')\n",
    "    print('F1 = {:.2f}%, Precision = {:.2f}%, Recall = {:.2f}%'.format(f, precision, recall))\n",
    "    \n",
    "    f, precision, recall = evaluate_model(model, test_batches, idx_tag)\n",
    "    \n",
    "    print('================================== Test  Data ==================================')\n",
    "    print('F1 = {:.2f}%, Precision = {:.2f}%, Recall = {:.2f}%'.format(f, precision, recall))\n",
    "    \n",
    "    finish_time = time.time()\n",
    "    \n",
    "    print('Time: {:.2f}s\\n'.format(finish_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvMWv8qllePQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
